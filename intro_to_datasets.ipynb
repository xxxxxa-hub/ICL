{"cells":[{"cell_type":"code","execution_count":null,"id":"83ad85fd-3ede-4dc2-98d9-915fbb8a1836","metadata":{"id":"83ad85fd-3ede-4dc2-98d9-915fbb8a1836"},"outputs":[],"source":["from ICL_modules import data_loader, dataset_interface, s_random, experiment_basics, functions\n","from ICL_inference import inference\n","from ICL_calibrations import calibration_methods,new_calib\n","from run import run_multiple_calibration_experiments_generic\n","from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    LogitsProcessorList,\n","    LogitsProcessor\n",")\n","import random\n","import torch\n","import numpy as np\n","import pandas as pd\n","import itertools\n","import functools\n","import copy"]},{"cell_type":"markdown","source":["# Intro to Package"],"metadata":{"id":"C8glN03nemul"},"id":"C8glN03nemul"},{"cell_type":"code","execution_count":null,"id":"3fda5d1b-ec73-4ba0-b387-5d2bc4b5b297","metadata":{"id":"3fda5d1b-ec73-4ba0-b387-5d2bc4b5b297"},"outputs":[],"source":["# Load the SST-2 sentiment analysis dataset from the GLUE benchmark.\n","# 'from_cache=True' ensures faster loading by using a locally cached version if available.\n","sst_2 = data_loader.glue_sst2(from_cache=True)"]},{"cell_type":"code","execution_count":null,"id":"59ce1924-5f0c-4c44-a2f4-84dada728fe6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59ce1924-5f0c-4c44-a2f4-84dada728fe6","executionInfo":{"status":"ok","timestamp":1743853732057,"user_tz":240,"elapsed":21,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"9eea0da0-1f13-409d-b6fc-17fe6152ac9d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['negative', 'positive']"]},"metadata":{},"execution_count":4}],"source":["# Retrieve the list of possible labels in the dataset.\n","# For SST-2, the labels represent sentiment: 'negative' or 'positive'.\n","sst_2.get_label_space()"]},{"cell_type":"code","source":["# Get the corresponding numerical index of each label.\n","# This is useful for training models where labels need to be in integer form.\n","sst_2.find_index_from_label('negative'),sst_2.find_index_from_label('positive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLAAC5JhkQt1","executionInfo":{"status":"ok","timestamp":1743853733621,"user_tz":240,"elapsed":31,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"d1bd86c2-94d9-4a44-b118-ee39e06dc07e"},"id":"aLAAC5JhkQt1","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 1)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# Convert label indices back to their corresponding text labels.\n","# This is useful when interpreting model predictions or displaying results.\n","sst_2.label_index_to_text(0),sst_2.label_index_to_text(1)"],"metadata":{"id":"SqKHa1N0mevz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743853734377,"user_tz":240,"elapsed":24,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"1f681ae3-cf35-499a-d7f8-24e5bbaeedff"},"id":"SqKHa1N0mevz","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('negative', 'positive')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"id":"7afa9650-6e78-4125-a02f-575ecf5b0542","metadata":{"collapsed":true,"id":"7afa9650-6e78-4125-a02f-575ecf5b0542","outputId":"ba738935-1ff5-4d1f-f583-4c40631a63c5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743853741455,"user_tz":240,"elapsed":27,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[([', painful , obnoxious '], 0),\n"," (['the lady and the duke surprisingly '], 1),\n"," (['hoping for a stiff wind '], 0),\n"," (['woven together skilfully '], 1)]"]},"metadata":{},"execution_count":8}],"source":["# Retrieve the dataset in the form of a list of tuples: [([text], label_index)]\n","# Each item is a single data sample:\n","#   - [text]: a list containing the sentence\n","#   - label_index: 0 for 'negative', 1 for 'positive'\n","sst_2.get_dataset()[:4]"]},{"cell_type":"code","execution_count":null,"id":"60bf4b41-8d1b-4c64-825d-c8bbee8a8f80","metadata":{"id":"60bf4b41-8d1b-4c64-825d-c8bbee8a8f80","outputId":"78fc6f17-3210-4937-bf67-c6103af43bf4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743853747926,"user_tz":240,"elapsed":7,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['woven together skilfully '], 'positive')"]},"metadata":{},"execution_count":9}],"source":["# Access the 4th data example in the dataset.\n","# get_input_text(3): returns the text of the 4th sample\n","# get_label(3): returns the label index (e.g., 0 or 1) of the 4th sample\n","sst_2.get_input_text(3), sst_2.get_label(3)"]},{"cell_type":"code","execution_count":null,"id":"9775e30a-f77b-4d5d-b708-7ef87d86c0c5","metadata":{"id":"9775e30a-f77b-4d5d-b708-7ef87d86c0c5"},"outputs":[],"source":["# Define the number of test samples and calculate the number of demonstration samples accordingly\n","test_samples = 512\n","dem_samples = len(sst_2) - test_samples  # Total dataset size minus test size\n","\n","# Define the number of ICL examples (i.e k-shot)\n","k = 4\n","seed= 107\n","# Initialize a DatasetSplitter instance to handle train/test splits and k-shot setting\n","splitted_sst2 = dataset_interface.DatasetSplitter(sst_2, dem_samples, test_samples, seed)"]},{"cell_type":"code","execution_count":null,"id":"ae01024e-3073-4813-b23d-baf2fd1fd5e0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ae01024e-3073-4813-b23d-baf2fd1fd5e0","executionInfo":{"status":"ok","timestamp":1743853762105,"user_tz":240,"elapsed":26,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"d0eaf82b-6846-4856-f43a-402be28d91fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(['delightfully rendered '], 1),\n"," (['bewilderingly brilliant and '], 1),\n"," (['a beyond-lame satire , '], 0),\n"," (['engrossing portrait '], 1)]"]},"metadata":{},"execution_count":11}],"source":["# This is the *demonstration set* used for k-shot in-context learning (ICL).\n","# For example, if k=4, we randomly sample 4 examples (text + label) from the dataset.\n","# These 4 examples will be shown to the model as demonstrations, mimicking a few-shot learning setup.\n","# Important: After sampling these, we will no longer use or access this portion of the data.\n","# So we effectively only have 4 training examples in the ICL context.\n","splitted_sst2.demonstration.get_dataset()[:4]"]},{"cell_type":"code","execution_count":null,"id":"e0dc93a0-97e0-46f2-a246-cac5b0510ff3","metadata":{"collapsed":true,"id":"e0dc93a0-97e0-46f2-a246-cac5b0510ff3","outputId":"2f34d193-0d55-4339-a681-b12f1ca83573","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743853768382,"user_tz":240,"elapsed":8,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(['with weak dialogue and biopic '], 0),\n"," (['more bizarre than '], 0),\n"," (['a charming , funny and beautifully crafted import '], 1),\n"," (['are the difference between this and countless other flicks about guys and dolls '],\n","  1)]"]},"metadata":{},"execution_count":12}],"source":["# This is the test set, which is held out and never seen during training or demonstration sampling.\n","# After running the training or few-shot inference (e.g. via in-context learning),\n","# we evaluate the model's performance on this set.\n","splitted_sst2.test.get_dataset()[:4]"]},{"cell_type":"code","execution_count":null,"id":"aa0ffeb2-582b-43db-92af-e682e88a8d86","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa0ffeb2-582b-43db-92af-e682e88a8d86","executionInfo":{"status":"ok","timestamp":1743853772393,"user_tz":240,"elapsed":9,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"50b54ea8-bd50-4afd-d241-b346ccef855f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('negative', 'positive')"]},"metadata":{},"execution_count":13}],"source":["# Get the text label ('positive' or 'negative') of the 1st sample in the test and demonstration set\n","splitted_sst2.test.get_label(0), splitted_sst2.demonstration.get_label(0)"]},{"cell_type":"code","execution_count":null,"id":"8b8967a4-c722-454e-9705-2cfced52347c","metadata":{"id":"8b8967a4-c722-454e-9705-2cfced52347c","outputId":"09359f0a-325f-4cf0-b9ce-3263ffcef381","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1743853777513,"user_tz":240,"elapsed":11,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'positive'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["# Get the *ground truth label* of a specific sample.\n","# You can choose whether to fetch from the test set or the training set using test_set=True/False.\n","\n","# Label of the 1st sample in the test set\n","splitted_sst2.get_ground_truth_label(0, test_set=True),\n","\n","# Label of the 1st sample in the training set\n","splitted_sst2.get_ground_truth_label(0, test_set=False)"]},{"cell_type":"code","source":["# This cell constructs a prompt string for k-shot in-context learning (ICL)\n","# using the `prompt_writter()` method.\n","\n","# What is this for?\n","# The resulting prompt is used to guide a language model in predicting the sentiment\n","# of a test sentence by showing it a few labeled examples beforehand.\n","\n","# Explanation of what's happening:\n","# The first argument to `prompt_writter()` is a list of demonstration examples in the format:\n","#     ([input_text], label_text)\n","# Each demonstration example consists of:\n","#   - input_text: the sentence as a list of tokens/words\n","#   - label_text: the corresponding sentiment label ('positive' or 'negative')\n","\n","# This list comprehension:\n","#     [ (splitted_sst2.demonstration.get_input_text(i), splitted_sst2.demonstration.get_label(i)) for i in [2019, 4761, 3483, 3952] ]\n","# does the following:\n","#   - It selects 4 specific examples from the demonstration set, using their indices.\n","#   - These indices [2019, 4761, 3483, 3952] were  chosen randomly in experiments\n","#     and represent the k=4 examples we want to show the model.\n","#   - For each index `i`, it gets the sentence and its label.\n","\n","# The second argument to `prompt_writter()`:\n","#     splitted_sst2.test.get_input_text(0)\n","# fetches the input text (as a list) of the first test sample â€” the sentence we want the model to label.\n","\n","# Output format:\n","# The resulting prompt will look like:\n","#     sentence: demo1_text    sentiment: label1\n","#     sentence: demo2_text    sentiment: label2\n","#     ...\n","#     sentence: test_text     sentiment:\n","#\n","# The model is expected to complete the last line with a predicted sentiment.\n","\n","splitted_sst2.prompt_writter([(splitted_sst2.demonstration.get_input_text(i),splitted_sst2.demonstration.get_label(i)) for i in [2019, 4761, 3483, 3952]],\n","                             splitted_sst2.test.get_input_text(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"WZyYK8wSv4Y5","executionInfo":{"status":"ok","timestamp":1743853785613,"user_tz":240,"elapsed":12,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"7b6dfac8-1e48-4303-f2be-51bf2cace56f"},"id":"WZyYK8wSv4Y5","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'sentence: establishes itself as a durable part of the movie landscape : a james bond series for kids  sentiment: positive\\nsentence: no-holds-barred cinematic  sentiment: positive\\nsentence: this odd , poetic road movie , spiked by jolts of pop music  sentiment: positive\\nsentence: comes the first lousy guy ritchie imitation .  sentiment: negative\\nsentence: with weak dialogue and biopic  sentiment:  '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":null,"id":"2650c030-bdff-4614-8640-fb4cb89e9c86","metadata":{"id":"2650c030-bdff-4614-8640-fb4cb89e9c86"},"outputs":[],"source":["# Create an Experiment object for SST-2 using the previously split dataset\n","# and the desired k-shot configuration.\n","#\n","# `Experiment` is a utility class designed to:\n","# - Manage the overall experiment setup\n","# - Automatically handle prompt construction\n","# - Interface with test samples\n","#\n","# Arguments:\n","#   splitted_sst2 : the dataset wrapper that holds train/test/demonstration splits\n","#   k             : the number of in-context examples to use in each prompt\n","#\n","# This object will make it easier to run multiple test samples systematically.\n","\n","sst2_experiment = experiment_basics.Experiment(splitted_sst2, k=k, seed=seed)\n"]},{"cell_type":"code","execution_count":null,"id":"53a000c2-9383-4611-a1e9-300885d267f8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"53a000c2-9383-4611-a1e9-300885d267f8","executionInfo":{"status":"ok","timestamp":1743853798705,"user_tz":240,"elapsed":27,"user":{"displayName":"Korel GÃœNDEM","userId":"08294952992008379301"}},"outputId":"8c8ca303-4df1-4dc5-80a9-816227f23809"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"sentence: a tendency to sag in certain places  sentiment: negative\\nsentence: authentic christmas spirit  sentiment: positive\\nsentence: mixed messages ,  sentiment: negative\\nsentence: far from heaven is a dazzling conceptual feat , but more than that , it 's a work of enthralling drama .  sentiment: positive\\nsentence: with weak dialogue and biopic  sentiment:  \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["# ðŸ‘‡ Generate a prompt for a specific test sample (in this case, index 0)\n","#\n","# This method:\n","# - Samples k demonstration examples automatically (no need to manually specify indices)\n","# - Retrieves the input sentence at test index 0\n","# - Constructs a full ICL prompt of the form:\n","#\n","#     sentence: demo1_text  sentiment: label1\n","#     sentence: demo2_text  sentiment: label2\n","#     ...\n","#     sentence: test_input_text  sentiment:\n","#\n","# This prompt can now be sent to a language model to predict the sentiment\n","# of the final test sentence.\n","#\n","# Note: This abstracts away the manual pairing and formatting from earlier cells.\n","\n","sst2_experiment.get_prompts_for_test_sample(0)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[],"machine_shape":"hm"}},"nbformat":4,"nbformat_minor":5}
